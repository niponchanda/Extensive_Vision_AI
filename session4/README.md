**Hand written MNIST Datasets**

**Epoch**: 20

**Parameters**: 17, 146

**Accuracy**: 99.40 at epoch 14

**LOGS**



================================================================
Total params: 17,146
Trainable params: 17,146
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 1.21
Params size (MB): 0.07
Estimated Total Size (MB): 1.28
----------------------------------------------------------------


Epoch: 1, Learning rate: 0.01
loss=0.3528384268283844 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.25it/s]

Test set: Average loss: 0.1047, Accuracy: 9753/10000 (97.5300%)

Epoch: 2, Learning rate: 0.01
loss=0.2628697454929352 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.08it/s]

Test set: Average loss: 0.0668, Accuracy: 9825/10000 (98.2500%)

Epoch: 3, Learning rate: 0.01
loss=0.1603519767522812 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.26it/s]

Test set: Average loss: 0.0546, Accuracy: 9851/10000 (98.5100%)

Epoch: 4, Learning rate: 0.01
loss=0.18687386810779572 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.03it/s]

Test set: Average loss: 0.0391, Accuracy: 9898/10000 (98.9800%)

Epoch: 5, Learning rate: 0.01
loss=0.231159508228302 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 18.94it/s]

Test set: Average loss: 0.0386, Accuracy: 9897/10000 (98.9700%)

Epoch: 6, Learning rate: 0.01
loss=0.15329565107822418 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.28it/s]

Test set: Average loss: 0.0350, Accuracy: 9906/10000 (99.0600%)

Epoch: 7, Learning rate: 0.01
loss=0.11015485972166061 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.19it/s]

Test set: Average loss: 0.0313, Accuracy: 9907/10000 (99.0700%)

Epoch: 8, Learning rate: 0.01
loss=0.11289023607969284 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 18.93it/s]

Test set: Average loss: 0.0257, Accuracy: 9924/10000 (99.2400%)

Epoch: 9, Learning rate: 0.01
loss=0.08084426075220108 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.26it/s]

Test set: Average loss: 0.0260, Accuracy: 9926/10000 (99.2600%)

Epoch: 10, Learning rate: 0.01
loss=0.14622509479522705 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.10it/s]

Test set: Average loss: 0.0253, Accuracy: 9926/10000 (99.2600%)

Epoch: 11, Learning rate: 0.01
loss=0.09205582737922668 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.05it/s]

Test set: Average loss: 0.0250, Accuracy: 9924/10000 (99.2400%)

Epoch: 12, Learning rate: 0.000665336
loss=0.15459249913692474 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 18.99it/s]

Test set: Average loss: 0.0224, Accuracy: 9936/10000 (99.3600%)

Epoch: 13, Learning rate: 0.0006213753
loss=0.10708384960889816 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 18.99it/s]

Test set: Average loss: 0.0212, Accuracy: 9938/10000 (99.3800%)

Epoch: 14, Learning rate: 0.0005828638
loss=0.14046739041805267 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.16it/s]

Test set: Average loss: 0.0216, Accuracy: 9940/10000 (99.4000%)

Epoch: 15, Learning rate: 0.0005488474
loss=0.17299716174602509 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.11it/s]

Test set: Average loss: 0.0213, Accuracy: 9940/10000 (99.4000%)

Epoch: 16, Learning rate: 0.0005185825
loss=0.0952337309718132 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.61it/s]

Test set: Average loss: 0.0209, Accuracy: 9945/10000 (99.4500%)

Epoch: 17, Learning rate: 0.000491481
loss=0.19986842572689056 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 18.82it/s]

Test set: Average loss: 0.0210, Accuracy: 9938/10000 (99.3800%)

Epoch: 18, Learning rate: 0.0004670715
loss=0.11516765505075455 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 19.18it/s]

Test set: Average loss: 0.0219, Accuracy: 9942/10000 (99.4200%)

Epoch: 19, Learning rate: 0.0004449718
loss=0.10677972435951233 batch_id=468: 100%|██████████| 469/469 [00:25<00:00, 18.74it/s]

Test set: Average loss: 0.0205, Accuracy: 9942/10000 (99.4200%)

Epoch: 20, Learning rate: 0.000424869
loss=0.09717757254838943 batch_id=468: 100%|██████████| 469/469 [00:24<00:00, 18.97it/s]

Test set: Average loss: 0.0212, Accuracy: 9942/10000 (99.4200%)
